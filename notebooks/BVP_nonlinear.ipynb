{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A nonlinear BVP\n",
    "\n",
    "[AMath 585, Winter Quarter 2020](http://staff.washington.edu/rjl/classes/am585w2020/) at the University of Washington. Developed by R.J. LeVeque and distributed under the [BSD license](https://github.com/rjleveque/amath585w2020/blob/master/LICENSE).  You are free to modify and use as you please, with attribution.\n",
    "\n",
    "These notebooks are all [available on Github](https://github.com/rjleveque/amath585w2020/).\n",
    "\n",
    "-----\n",
    "\n",
    "Solve the nonlinear BVP\n",
    "$$\n",
    "\\epsilon u''(x) + u(x)(u'(x) - 1) = f(x)\n",
    "$$\n",
    "with Dirichlet boundary conditions.\n",
    "\n",
    "In this notebook we illustrate with a large value of $\\epsilon$ and a \"manufactured solution\" to test the code is working.  Later we will look at the singular perturbation version with $\\epsilon$ very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "There are a few debugging statements left in the code below from when I was getting this working, and some illustration below of how print statements can be used to aid in debugging a complex routine like this.\n",
    "\n",
    "One of the hardest things about getting this code right is the array indexing, and making sure that you understand how Numpy array slicing works.  See the notebook [Numpy_array_hints.ipynb](Numpy_array_hints.ipynb) for some tips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the BVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_bvp_nonlinear(epsilon, f, ainfo, binfo, m, u0_func, max_iter=10, \n",
    "                        plot_iterates=True, debug=False):\n",
    "    \"\"\"\n",
    "    Solve the 2-point BVP with Dirichlet BCs\n",
    "    Input:\n",
    "        epsilon > 0 coefficient of u''\n",
    "        f is a function defining the right hand side,\n",
    "        ainfo = (ax, alpha) defines the Dirichlet boundary condition u(ax) = alpha,\n",
    "        binfo = (bx, beta) defines the Dirichlet boundary condition u(bx) = beta,\n",
    "        m is the number of (equally spaced) interior grid points to use.\n",
    "        u0_func = function to evaluation for initial guess\n",
    "        max_iter = maximum number of iterations of Newton\n",
    "        plot_iterates: if set to True, plot the approximate solution each iteration\n",
    "        debug: if set to True, print some things out including the matrix at each\n",
    "            iteration, so generally use this only for small m.\n",
    "    \n",
    "    Returns:\n",
    "        x = array of grid points (including boundaries, so of length m+2)\n",
    "        u = array of approximate solution at these points.\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy import sparse\n",
    "    from scipy.sparse.linalg import spsolve\n",
    "        \n",
    "    ax, alpha = ainfo\n",
    "    bx, beta = binfo\n",
    "    \n",
    "    h = (bx-ax)/float(m+1)    # h = delta x\n",
    "    x = linspace(ax,bx,m+2)   # note x[0]=ax, x[m+1]=bx\n",
    "    if debug: \n",
    "        print('+++ h = %g, m+2 = %i' % (h,m+2))\n",
    "        print('+++ x = ',x)\n",
    "    \n",
    "    # convergence tolerances:\n",
    "    tol_delta = 1e-12\n",
    "    tol_Gk = 1e-12\n",
    "    \n",
    "    # set up m by m matrix A for the u''(x) term, \n",
    "    # which is always needed as part of the Jacobian\n",
    "    A_diag = ones(m+2)\n",
    "    A_offdiag = ones(m+1)\n",
    "    A = sparse.diags([A_offdiag, -2*A_diag, A_offdiag], [-1, 0, 1], \n",
    "                     shape=(m+2,m+2), format='csc')\n",
    "    A = epsilon * A / h**2\n",
    "    \n",
    "    # modify first and last row for Dirichlet BCs:\n",
    "    A[0,0] = 1.\n",
    "    A[0,1] = 0.\n",
    "    A[m+1,m] = 0.\n",
    "    A[m+1,m+1] = 1.\n",
    "    \n",
    "    # initial guess for Newton iteration:\n",
    "    Uk = u0_func(x)  # of length m+2\n",
    "    if debug: print('+++ Initial Uk = ', Uk)\n",
    "    \n",
    "    if plot_iterates:\n",
    "        # make a plot showing how the solution evolves:\n",
    "        fig = figure(figsize=(8,6))\n",
    "        ax = axes()\n",
    "        grid(True)\n",
    "        title('Approximate solution while iterating')\n",
    "    \n",
    "    # Newton iteration:\n",
    "    for k in range(max_iter):\n",
    "        \n",
    "        if plot_iterates:\n",
    "            plot(x,Uk,label='k = %i' % k)\n",
    "        \n",
    "        U = Uk.copy()  # use in slicing below so Uk not changed\n",
    "\n",
    "        # Jacobian matrix with be A from above plus nonlinear part N:\n",
    "        \n",
    "        N_subdiag = -U[1:m+2]\n",
    "        N_subdiag[m] = 0.\n",
    "        N_diag = zeros(m+2)\n",
    "        N_diag[1:m+1] = U[2:m+2] - U[0:m] - 2*h\n",
    "        N_superdiag = U[0:m+1]\n",
    "        N_superdiag[0] = 0.\n",
    "        N = sparse.diags([N_subdiag, N_diag, N_superdiag], [-1, 0, 1], \n",
    "                     shape=(m+2,m+2), format='csc')\n",
    "        N = N / (2*h)\n",
    "        \n",
    "        Jk = A + N\n",
    "        if debug: print('+++ after forming Jk, Uk = ', Uk)\n",
    "        if debug: print('+++ Jk = \\n', Jk.toarray())\n",
    "        \n",
    "        # Use Uk below, since U got changed above.\n",
    "        Gk = zeros(m+2)\n",
    "        if debug: print('+++ Uk[0] = %g, alpha = %g' % (Uk[0], alpha))\n",
    "        Gk[0] = Uk[0] - alpha\n",
    "        Gk[m+1] = Uk[m+1] - beta\n",
    "        Gk[1:m+1] = epsilon/h**2 * (Uk[0:m] - 2*Uk[1:m+1] + Uk[2:m+2]) \\\n",
    "                    + Uk[1:m+1] * ((Uk[2:m+2] - Uk[0:m])/(2*h) -1.) \\\n",
    "                    - f(x[1:m+1])\n",
    "        \n",
    "        # solve linear system:\n",
    "        if debug: print('+++ Uk = ',Uk)\n",
    "        if debug: print('+++ Gk = ',Gk)\n",
    "        delta = spsolve(Jk, Gk)\n",
    "        Uk = Uk - delta\n",
    "        if debug: print('+++ delta = ',delta)\n",
    "        norm_delta = norm(delta, inf)\n",
    "        norm_Gk = norm(Gk, inf)\n",
    "        print('Iteration k = %i: norm(Gk) = %.2e, norm(delta) = %.2e' \\\n",
    "               % (k, norm_Gk, norm_delta))\n",
    "        if (norm_delta < tol_delta) or (norm_Gk < tol_Gk):\n",
    "            print('Declared convergence after %i iterations' % k)\n",
    "            break\n",
    "        if k==(max_iter-1):\n",
    "            print('Reached max_iter, possible nonconvergence')\n",
    "    \n",
    "    if plot_iterates:\n",
    "        legend()\n",
    "        \n",
    "    return x,Uk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a manufactured solution\n",
    "\n",
    "We choose our desired solution $u(x)$ and then set $f(x)$ and $\\alpha, \\beta$ accordingly.\n",
    "\n",
    "Since the truncation error depends only on $u''''(x)$ and higher order derivatives, first try $u(x) = 3 + 4x^4$ so the truncation error (and hence the global error) should be 0, i.e. we expect the solution of the nonlinear system to be equal to the true solution evaluated at each grid point.  This tests that the Newton iteration is working.\n",
    "\n",
    "Note that we chose a function for which the boundary conditions are not just 0 and a value $\\epsilon \\neq 1$ to catch bugs in how these are specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utrue = lambda x: 3 + 4*x**2  # values below set based on this desired solution\n",
    "epsilon = 2.\n",
    "f = lambda x: 8*epsilon + (3 + 4*x**2)*(8*x-1.)\n",
    "ax = 0.; alpha = 3.; ainfo = (ax, alpha)\n",
    "bx = 1.; beta = 7.;   binfo = (bx, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfine = linspace(ax, bx, 1001)\n",
    "ufine = utrue(xfine)\n",
    "plot(xfine, ufine, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it works if we start with the true solution as our initial guess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 49\n",
    "u0_func = lambda x: 3 + 4*x**2\n",
    "x,u = solve_bvp_nonlinear(epsilon, f, ainfo, binfo, m, u0_func)\n",
    "\n",
    "# add true solution to plot\n",
    "plot(x, utrue(x), 'k+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a different initial guess\n",
    "\n",
    "If we don't know the true solution, one possible initial guess is simply the linear function that connects the two boundary conditions.  We know this will be close to correct very near the boundaries at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 49\n",
    "u0_func = lambda x: 3 + 4*x\n",
    "x,u = solve_bvp_nonlinear(epsilon, f, ainfo, binfo, m, u0_func)\n",
    "\n",
    "# add true solution to plot\n",
    "plot(x, utrue(x), 'k+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the quadratic convergence of Newton's method, as expected.  \n",
    "\n",
    "###  If the Jacobian is wrong:\n",
    "\n",
    "If you purposely introduce an error in specifying the Jacobian matrix, you would see this deteriorate.  For example if you change the line in the code from\n",
    "\n",
    "    N_diag[1:m+1] = U[2:m+2] - U[0:m] - 2*h\n",
    "    \n",
    "to\n",
    "\n",
    "    N_diag[1:m+1] = U[2:m+2] - U[0:m]\n",
    "    \n",
    "(forgetting the $-1$ in the $u(x)(u'(x)-1)$ term of the ODE, as I initially did), and rerun the cell above, you will see only linear convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different initial conditions\n",
    "\n",
    "Also let's try starting with an initial guess that is farther from correct, and in particular that does not even satisfy the boundary conditions.  Note from the plots below that in one iteration Newton has corrected these, since the two equations specifying the BCs are decoupled from the others and are both linear equations.\n",
    "\n",
    "(Note: If you try an initial condition a lot farther away from the true solution, you might see non-convergence.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 49\n",
    "u0_func = lambda x: cos(3*pi*x)\n",
    "x,u = solve_bvp_nonlinear(epsilon, f, ainfo, binfo, m, u0_func)\n",
    "\n",
    "# add true solution to plot\n",
    "plot(x, utrue(x), 'k+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global error:\n",
    "\n",
    "We chose the manufactured solution so that the global error should be zero, no matter how coarse our grid is.  Check that it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = norm(u-utrue(x), inf)\n",
    "print('Max-norm of error is %g' % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test convergence\n",
    "\n",
    "Now that we think Newton's method is converging properly, let's try a problem where the true solution is less smooth and so we expect a non-zero global error, but hopefully second-order accurate as we refine the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utrue = lambda x: sin(10*x+2)  # values below set based on this desired solution\n",
    "epsilon = 2.\n",
    "f = lambda x: -100*epsilon*sin(10*x+2) + sin(10*x+2) * (10*cos(10*x+2) - 1)\n",
    "ax = 0.; alpha = utrue(ax); ainfo = (ax, alpha)\n",
    "bx = 2.; beta = utrue(bx);   binfo = (bx, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfine = linspace(ax, bx, 1001)\n",
    "ufine = utrue(xfine)\n",
    "plot(xfine, ufine, 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 49\n",
    "u0_func = lambda x: alpha + x * (beta-alpha) / (bx-ax)\n",
    "x,u = solve_bvp_nonlinear(epsilon, f, ainfo, binfo, m, u0_func)\n",
    "\n",
    "# add true solution to plot\n",
    "plot(x, utrue(x), 'k+')\n",
    "\n",
    "error = norm(u-utrue(x), inf)\n",
    "print('Max-norm of error is %g' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values of m+1:\n",
    "mp1_vals = array([50, 100, 200, 400, 1000, 10000, 100000, 1000000])\n",
    "h_vals = (bx - ax) / mp1_vals   # correspoinding h values\n",
    "\n",
    "errors = []\n",
    "for jtest in range(len(mp1_vals)):\n",
    "    m = mp1_vals[jtest] - 1\n",
    "    print('Solving with m = %i' % m)\n",
    "    h = h_vals[jtest]\n",
    "    x,u = solve_bvp_nonlinear(epsilon, f, ainfo, binfo, m, \n",
    "                              u0_func, plot_iterates=False)\n",
    "    \n",
    "    x_true = linspace(ax, bx, m+2)\n",
    "    u_true = utrue(x_true)\n",
    "    error_max = abs(u - u_true).max()\n",
    "    errors.append(error_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with a million grid points the rounding error may be starting to affect convergence, but even for this grid we continue to see the expected error when plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglog(h_vals, errors, 'bx-', label='Observed errors')\n",
    "grid(True)\n",
    "xlabel('h = Delta x')\n",
    "ylabel('max norm of error')\n",
    "\n",
    "eref = h_vals**2\n",
    "loglog(h_vals, eref, 'r-', label='Reference line of slope 2')\n",
    "legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "To check if the matrix is being built properly, you might want to print things out for a small value of `m` and with special values of the input. For example, the cell below checks the nonlinear part of the Jacobian (since `epsilon = 0`) and the interval is chosen so that `h=1`.  Note that we also just take one iteration (`max_iter = 1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.\n",
    "f = lambda x: zeros(x.shape)\n",
    "ax = 0.; alpha = 0.; ainfo = (ax, alpha)\n",
    "bx = 5.; beta = 0.;   binfo = (bx, beta)\n",
    "\n",
    "m = 4\n",
    "u0_func = lambda x: x\n",
    "x,u = solve_bvp_nonlinear(epsilon, f, ainfo, binfo, m, u0_func, \n",
    "                          max_iter=1, plot_iterates=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
